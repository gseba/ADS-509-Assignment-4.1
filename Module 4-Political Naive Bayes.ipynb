{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text\n",
    "### Ghassan Seba\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import os\n",
    "import contextlib\n",
    "import string\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import sys\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download NLTK data\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "    \n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Text preprocessing functions\n",
    "def lemmatize(tokens):\n",
    "    \"\"\"Lemmatizes tokens.\"\"\"\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "# Define stopwords to retain\n",
    "retain_words = {'about'}  \n",
    "\n",
    "def remove_stop(tokens):\n",
    "    \"\"\"Removes stop words except those in the retain_words set.\"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return [word for word in tokens if word not in stop_words or word in retain_words]\n",
    "    \n",
    "def remove_punctuation(text, punct_set=set(string.punctuation)):\n",
    "    \"\"\"Removes punctuation.\"\"\"\n",
    "    return \"\".join([ch for ch in text if ch not in punct_set])\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"Tokenizes text.\"\"\"\n",
    "    collapse_whitespace = re.compile(r'\\s+')\n",
    "    return collapse_whitespace.split(text)\n",
    "\n",
    "def prepare(text, pipeline):\n",
    "    \"\"\"Applies transformations to text.\"\"\"\n",
    "    text = remove_punctuation(text)\n",
    "    text = text.lower()  \n",
    "    tokens = tokenize(text)\n",
    "    for transform in pipeline:\n",
    "        tokens = transform(tokens)  \n",
    "    return tokens\n",
    "\n",
    "def clean_text(text):\n",
    "    # Chnage emojis to text\n",
    "    text = emoji.demojize(text)\n",
    "\n",
    "    # Remove 'b' and quotes at the start of the string\n",
    "    text = re.sub(r'^b[\\'\\\"]', '', text)\n",
    "\n",
    "    # Replace byte-encoded characters\n",
    "    text = text.replace('xe2x80x99', \"'\")  # Apostrophe\n",
    "    text = text.replace('xe2x80x9c', '\"').replace('xe2x80x9d', '\"')  # Double quotes\n",
    "    text = text.replace('xe2x80x94', '-')  # Em dash\n",
    "    text = text.replace('xe2x80x93', '-')  # En dash\n",
    "    text = text.replace('xe2x80xa6', '...')  # Ellipsis\n",
    "    text = text.replace('xf0x9fx87xba', 'ðŸ‡ºðŸ‡¸')  # Flag emoji\n",
    "    text = text.replace('xf0x9fx98x82', 'ðŸ˜‚')  # Laughing emoji\n",
    "    \n",
    "    # Remove sequences of text that have an x followed by 2 digits\n",
    "    text = re.sub(r'\\\\x\\w{2}', '', text)\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Define transformation pipeline\n",
    "pipeline = [remove_stop, lemmatize]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conventions',)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a list of all table names\n",
    "convention_cur.execute(\"SELECT name FROM sqlite_schema WHERE type='table' AND name NOT LIKE 'sqlite_%'\")\n",
    "table_names = convention_cur.fetchall()\n",
    "\n",
    "# Display Table Names\n",
    "table_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'party', 'TEXT', 0, None, 0),\n",
       " (1, 'night', 'INTEGER', 0, None, 0),\n",
       " (2, 'speaker', 'TEXT', 0, None, 0),\n",
       " (3, 'speaker_count', 'INTEGER', 0, None, 0),\n",
       " (4, 'time', 'TEXT', 0, None, 0),\n",
       " (5, 'text', 'TEXT', 0, None, 0),\n",
       " (6, 'text_len', 'TEXT', 0, None, 0),\n",
       " (7, 'file', 'TEXT', 0, None, 0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get column names and types for the 'conventions' table\n",
    "convention_cur.execute(\"PRAGMA table_info(conventions)\")\n",
    "columns = convention_cur.fetchall()\n",
    "\n",
    "# Display Table Info\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill this list up with items that are themselves lists. \n",
    "- The first element in the sublist should be the cleaned and tokenized text in a single string.\n",
    "- The second element should be the party."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create to hold convention data\n",
    "convention_data = []\n",
    "\n",
    "# Query convention text and party info\n",
    "query_results = convention_cur.execute(\n",
    "                            '''\n",
    "                            SELECT text, party\n",
    "                            FROM conventions\n",
    "                            ''')\n",
    "\n",
    "# Process each row using the prepare function\n",
    "for row in query_results:\n",
    "    raw_text, party = row\n",
    "    tokens = prepare(raw_text, pipeline)\n",
    "    processed_text = \" \".join(tokens)\n",
    "    \n",
    "    # Add data to list\n",
    "    convention_data.append([processed_text, party])\n",
    "\n",
    "# Close database connection\n",
    "convention_db.close()\n",
    "\n",
    "# # Display processed data\n",
    "# for item in convention_data:\n",
    "#     print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['first generation american know dangerous socialist agenda mother mercedes special education teacher aguadilla puerto rico father also immigrant came nation pursuit american dream consider duty fight protect dream rioter must allowed destroy city human sex drug trafficker allowed cross border socialist policy destroyed place like cuba venezuela must take root city school want see socialized bidenharris future country take look california place immense wealth immeasurable innovation immaculate environment democrat turned land discarded heroin needle park riot street blackout home president trumpâ€™s america light thing donâ€™t dim build thing donâ€™t burn',\n",
       "  'Republican'],\n",
       " ['today beautiful daughter hope thriving twoyear old crystal fast approaching three year recovery dear friend constant inspiration others hold special place heart facing opioid addiction thatâ€™s iâ€™m enormously grateful president leadership fighting deadly enemy effort weâ€™re turning tide crisis addiction president trump declared opioid crisis public health emergency secured 6 billion new federal funding help american fight opioid abuse invested additional 100 million stop opioid crisis rural america move strike root problem implemented safer prescribing plan aimed reducing opioid prescription third within three year',\n",
       "  'Republican'],\n",
       " ['loved one weâ€™ve lost letâ€™s make america country cure cancer', 'Democratic'],\n",
       " ['best campaign going international', 'Republican'],\n",
       " ['following correction joe biden cancer moonshot', 'Democratic'],\n",
       " ['vermont senator bernie sander officially endorsed', 'Democratic'],\n",
       " ['thank mr president', 'Republican'],\n",
       " ['economy brink joe led recovery effort created million job including western pennsylvania leadership america bounced back longest economic expansion history',\n",
       "  'Democratic'],\n",
       " ['went many president one say best president weâ€™ve ever ever believe',\n",
       "  'Republican'],\n",
       " ['look everybody talk about middle class fact way middle class generate wealth overwhelmingly building equity home naturally get passed one generation next equity home',\n",
       "  'Democratic']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2247 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in convention_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text, fw):\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Empty dictionary for feature words\n",
    "    feature_dict = {}\n",
    "    \n",
    "    # Tokenize text into words\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Check if tokens are in feature words\n",
    "    for token in tokens:\n",
    "        if token in fw:\n",
    "            feature_dict[token] = True\n",
    "    \n",
    "    # Return the dictionary\n",
    "    return feature_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"donald is the president\",feature_words)==\n",
    "       {'donald':True,'president':True})\n",
    "assert(conv_features(\"people are american in america\",feature_words)==\n",
    "                     {'america':True,'american':True,\"people\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   china = True           Republ : Democr =     25.8 : 1.0\n",
      "             enforcement = True           Republ : Democr =     21.5 : 1.0\n",
      "                 destroy = True           Republ : Democr =     19.2 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.8 : 1.0\n",
      "                religion = True           Republ : Democr =     16.1 : 1.0\n",
      "                  medium = True           Republ : Democr =     14.9 : 1.0\n",
      "                 liberal = True           Republ : Democr =     14.0 : 1.0\n",
      "                 defense = True           Republ : Democr =     13.0 : 1.0\n",
      "                     isi = True           Republ : Democr =     13.0 : 1.0\n",
      "                 patriot = True           Republ : Democr =     13.0 : 1.0\n",
      "                    flag = True           Republ : Democr =     12.8 : 1.0\n",
      "                   trade = True           Republ : Democr =     12.7 : 1.0\n",
      "               greatness = True           Republ : Democr =     12.1 : 1.0\n",
      "                 abraham = True           Republ : Democr =     11.9 : 1.0\n",
      "                  defund = True           Republ : Democr =     11.9 : 1.0\n",
      "              regulation = True           Republ : Democr =     11.9 : 1.0\n",
      "               terrorist = True           Republ : Democr =     11.9 : 1.0\n",
      "               amendment = True           Republ : Democr =     10.9 : 1.0\n",
      "                 culture = True           Republ : Democr =     10.9 : 1.0\n",
      "               destroyed = True           Republ : Democr =     10.9 : 1.0\n",
      "                position = True           Republ : Democr =     10.9 : 1.0\n",
      "                   crime = True           Republ : Democr =     10.3 : 1.0\n",
      "                    mike = True           Republ : Democr =     10.3 : 1.0\n",
      "                preserve = True           Republ : Democr =     10.3 : 1.0\n",
      "                  record = True           Republ : Democr =     10.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "***One interesting aspect of the classifier's output is the partisan divide in the most informative features. This divide reflects talking points often emphasized by each party, underscoring the model's ability to capture some ideological differences.***\n",
    "\n",
    "### My Observations\n",
    "\n",
    "***The Naive Bayes classifier, with an accuracy of 48%, is performing below the level of random guessing. The most informative features, such as \"china\" and \"climate,\" do reflect distinct party language patterns. However, the low accuracy, indicates that the model is not effectively capturing the differences between the classes. We should consider improvements such as using n-grams, TF-IDF, or a more advanced classifier to enhance performance.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('websites',), ('candidate_data',), ('tweets',)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a list of all table names\n",
    "cong_cur.execute(\"SELECT name FROM sqlite_schema WHERE type='table' AND name NOT LIKE 'sqlite_%'\")\n",
    "table_names = cong_cur.fetchall()\n",
    "\n",
    "# Display Table Names\n",
    "table_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'district', 'TEXT', 0, None, 0),\n",
       " (1, 'candidate', 'TEXT', 0, None, 0),\n",
       " (2, 'pull_time', 'DATETIME', 0, None, 0),\n",
       " (3, 'tweet_time', 'DATETIME', 0, None, 0),\n",
       " (4, 'handle', 'TEXT', 0, None, 0),\n",
       " (5, 'is_retweet', 'INTEGER', 0, None, 0),\n",
       " (6, 'tweet_id', 'TEXT', 0, None, 0),\n",
       " (7, 'tweet_text', 'TEXT', 0, None, 0),\n",
       " (8, 'likes', 'INTEGER', 0, None, 0),\n",
       " (9, 'replies', 'INTEGER', 0, None, 0),\n",
       " (10, 'retweets', 'INTEGER', 0, None, 0),\n",
       " (11, 'tweet_ratio', 'REAL', 0, None, 0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get column names and types for the 'conventions' table\n",
    "cong_cur.execute(\"PRAGMA table_info(tweets)\")\n",
    "columns = cong_cur.fetchall()\n",
    "\n",
    "# Display Table Info\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'index', 'INTEGER', 0, None, 0),\n",
       " (1, 'student', 'TEXT', 0, None, 0),\n",
       " (2, 'state', 'TEXT', 0, None, 0),\n",
       " (3, 'district_num', 'TEXT', 0, None, 0),\n",
       " (4, 'formatted_dist_num', 'INTEGER', 0, None, 0),\n",
       " (5, 'abbrev', 'TEXT', 0, None, 0),\n",
       " (6, 'district', 'TEXT', 0, None, 0),\n",
       " (7, 'candidate', 'TEXT', 0, None, 0),\n",
       " (8, 'party', 'TEXT', 0, None, 0),\n",
       " (9, 'website', 'TEXT', 0, None, 0),\n",
       " (10, 'twitter_handle', 'TEXT', 0, None, 0),\n",
       " (11, 'incumbent', 'TEXT', 0, None, 0),\n",
       " (12, 'age', 'REAL', 0, None, 0),\n",
       " (13, 'gender', 'TEXT', 0, None, 0),\n",
       " (14, 'marital_status', 'TEXT', 0, None, 0),\n",
       " (15, 'white_non_hispanic', 'TEXT', 0, None, 0),\n",
       " (16, 'hispanic', 'TEXT', 0, None, 0),\n",
       " (17, 'black', 'TEXT', 0, None, 0),\n",
       " (18, 'partisian_lean_pvi', 'TEXT', 0, None, 0),\n",
       " (19, 'opposed', 'TEXT', 0, None, 0),\n",
       " (20, 'pct_urban', 'TEXT', 0, None, 0),\n",
       " (21, 'income', 'REAL', 0, None, 0),\n",
       " (22, 'region', 'TEXT', 0, None, 0)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get column names and types for the 'conventions' table\n",
    "cong_cur.execute(\"PRAGMA table_info(candidate_data)\")\n",
    "columns = cong_cur.fetchall()\n",
    "\n",
    "# Display Table Info\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process tweet data\n",
    "tweet_data = []\n",
    "\n",
    "# Apply text processing and encoding fix\n",
    "for row in results:\n",
    "    candidate, party, raw_tweet = row\n",
    "    raw_tweet = clean_text(str(raw_tweet))\n",
    "    tokens = prepare(raw_tweet, pipeline)\n",
    "    processed_tweet = \" \".join(tokens)\n",
    "    \n",
    "    # Store processed tweet and party\n",
    "    tweet_data.append([processed_tweet, party])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: earlier today spoke house floor abt protecting health care woman praised ppmarmonte work central coast \n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: go tribe rallytogether \n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: apparently trump think easy student overwhelmed crushing burden debt pay student loan trumpbudget \n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: grateful first responder rescue personnel firefighter police volunteer working tirelessly keep people safe provide muchneeded help putting life linenn\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: let make even greater kag \n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: about 1hr cavs tie series 22 im allin216 repbarbaralee scared roadtovictory\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: congrats belliottsd new gig sd city hall glad continue serve \n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: really close 3500 raised toward match right whoot thats 7000 nonmath major room help u get \n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: today comment period potuss plan expand offshore drilling opened public 60 day march 9 share oppose proposed program directly trump administration comment made email mail \n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: celebrated icseastlas 22 year eastside commitment amp saluted community leader last night award dinner \n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet, party in tweet_data_sample :\n",
    "   # Extract features\n",
    "    tweet_features = conv_features(tweet, feature_words)\n",
    "    \n",
    "    # Classify tweet\n",
    "    estimated_party = classifier.classify(tweet_features)\n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of counts by actual and estimated party\n",
    "parties = ['Republican', 'Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties:\n",
    "    for p1 in parties:\n",
    "        results[p][p1] = 0\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data):\n",
    "    tweet, party = tp    \n",
    "    \n",
    "    # Extract features and classify\n",
    "    tweet_features = conv_features(tweet, feature_words)\n",
    "    estimated_party = classifier.classify(tweet_features)\n",
    "    \n",
    "    # Update results\n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Results:\n",
      "\n",
      "                    Predicted Republican     Predicted Democratic     \n",
      "======================================================================\n",
      "Actual Republican   3776                     502                      \n",
      "Actual Democrat     4897                     827                      \n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Results:\\n\")\n",
    "print(f\"{' ':<20}{'Predicted Republican':<25}{'Predicted Democratic':<25}\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Actual Republican':<20}{results['Republican']['Republican']:<25}{results['Republican']['Democratic']:<25}\")\n",
    "print(f\"{'Actual Democrat':<20}{results['Democratic']['Republican']:<25}{results['Democratic']['Democratic']:<25}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Democratic Class: TP=827, FP=4897, FN=502, TN=3776\n",
      "Republican Class: TP=3776, FP=4897, FN=502, TN=827\n"
     ]
    }
   ],
   "source": [
    "# Democratic class values\n",
    "democrat_values = list(results['Democratic'].values())\n",
    "dem_FP = democrat_values[0]  \n",
    "dem_TP = democrat_values[1]  \n",
    "\n",
    "# Republican class values\n",
    "republican_values = list(results['Republican'].values())\n",
    "rep_TP = republican_values[0]  \n",
    "rep_FN = republican_values[1]  \n",
    "\n",
    "# Complementary values\n",
    "rep_FP = dem_FP  \n",
    "rep_TN = dem_TP \n",
    "dem_FN = rep_FN \n",
    "dem_TN = rep_TP  \n",
    "\n",
    "# Output\n",
    "print(f\"Democratic Class: TP={dem_TP}, FP={dem_FP}, FN={dem_FN}, TN={dem_TN}\")\n",
    "print(f\"Republican Class: TP={rep_TP}, FP={rep_FP}, FN={rep_FN}, TN={rep_TN}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Democratic</td>\n",
       "      <td>0.4602</td>\n",
       "      <td>0.1445</td>\n",
       "      <td>0.6223</td>\n",
       "      <td>0.2345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Republican</td>\n",
       "      <td>0.4602</td>\n",
       "      <td>0.4354</td>\n",
       "      <td>0.8827</td>\n",
       "      <td>0.5831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Class  Accuracy  Precision  Recall  F1 Score\n",
       "0  Democratic    0.4602     0.1445  0.6223    0.2345\n",
       "1  Republican    0.4602     0.4354  0.8827    0.5831"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to calculate metrics\n",
    "def calculate_metrics(tp, fp, fn, tn):\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Calculate metrics for Democratic and Republican classes\n",
    "dem_accuracy, dem_precision, dem_recall, dem_f1 = calculate_metrics(dem_TP, dem_FP, dem_FN, dem_TN)\n",
    "rep_accuracy, rep_precision, rep_recall, rep_f1 = calculate_metrics(rep_TP, rep_FP, rep_FN, rep_TN)\n",
    "\n",
    "# Create a DataFrame to store the metrics\n",
    "metrics_summary = {\n",
    "    \"Class\": [\"Democratic\", \"Republican\"],\n",
    "    \"Accuracy\": [dem_accuracy, rep_accuracy],\n",
    "    \"Precision\": [dem_precision, rep_precision],\n",
    "    \"Recall\": [dem_recall, rep_recall],\n",
    "    \"F1 Score\": [dem_f1, rep_f1]\n",
    "}\n",
    "\n",
    "# Create and display the DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_summary)\n",
    "\n",
    "# Round DataFrame to 4 decimal places\n",
    "metrics_df = metrics_df.round(4)\n",
    "\n",
    "# Display dataframe\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close database connection\n",
    "cong_db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "***The classifier seems to show uneven performance between the two classes, with better precision, recall, and F1 score for Republican tweets than Democratic ones. One possible reason for this could be the feature selection process, which includes words found in a predefined list (feature_words). If the selected list contains more words commonly used in Republican tweets, this could lead to better predictions for that class. This input list, perhaps containing more Republican tweets, may also be causing an imbalance and affecting the output, causing a skew in the classifier's performance. The text preprocessing step, while simplifying the data, could be removing important contextual information that helps distinguish between Democratic and Republican tweets. Although, when I attempted to run the model without removing the stop words, I received the same metrics. Ultimately, more testing is needed to improve the results.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>References:</b></center>\r\n",
    "\r\n",
    "- Tutorials Point. (2024). *SQLite - PRAGMA.* Tutorials Point. https://www.tutorialspoint.com/sqlite/sqlite_pragma.htm\r\n",
    "- Python Software Foundation. (2024). *sqlite3â€”DB-API 2.0 interface for SQLite databases.* Python Documentation. https://docs.python.org/3/library/sqlite3.html\r\n",
    "- Kumar, S. (2021, May 16). *How to execute a SQLite statement in Python?* GeeksforGeeks. https://www.geeksforgeeks.org/how-to-execute-a-sqlite-statement-in-python/\r\n",
    "- SQLite Tutorial. (n.d.). *SQLite select.* SQLite Tutorial. https://www.sqlitetutorial.net/sqlite-select/\r\n",
    "- SQLite Tutorial. (n.d.). *SQLite show tables.* SQLite Tutorial. https://www.sqlitetutorial.net/sqlite-show-tables/\r\n",
    "- Pankaj. (2022, August 3). *Python string encode() decode().* DigitalOcean. https://www.digitalocean.com/community/tutorials/python-string-encode-decode\r\n",
    "- Jain, Y. (2021, February 23). *How to convert a string to UTF-8 in Python?* Studytonight. https://www.studytonight.com/python-howtos/how-to-convert-a-string-to-utf8-in-python\r\n",
    "- Singh, V. K., & Obi Tulton, A. (2022, November 30). *How to work with Unicode in Python.* DigitalOcean. https://www.digitalocean.com/community/tutorials/how-to-work-with-unicode-in-python\r\n",
    "- Solomon, B. (2021, August 29). *demoji (Version 1.1.0)* [Python package]. PyPI. https://pypi.org/project/demoji/\r\n",
    "- pythontutorial.net. (2023). *Python regex sub().* https://www.pythontutorial.net/python-regex/python-regex-sub/\r\n",
    "- Unicode Table. (n.d.). *UTF-8 encoding table and Unicode characters: Code points U+2000 to U+207F.* Retrieved from https://www.utf8-chartable.de/unicode-utf8-table.pl?start=8192&number=128&utf8=string-literal\r\n",
    "- OpenAI. (2023). ChatGPT (September 29 version) [Large language model]. https://chat.openai.com/\r\n",
    "- Jablonski, J. (2023, October 18). *Python's F-String: An improved string interpolation and formatting tool.* Real Python. https://realpython.com/python-f-strings/\r\n",
    "- GeeksforGeeks. (2023, October 18). *Classification metrics using Sklearn.* GeeksforGeeks. https://www.geeksforgeeks.org/sklearn-classification-metrics/\r\n",
    "- Shah, F. P., & Patel, V. (2016). *A review on feature selection and feature extraction for text classification.* 2016 International Conference on Wireless Communications, Signal Processing and Networking (WiSPNET), 2264â€“2268. https://doi.org/10.1109/WiSPNET.2016.7566545"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
